Текущие задачи:
	
	1) В базу данных обучения записывать вместо всех встретившихся векторов, соответствующих данной фонеме, 
	записывать все матрицы размера n*k, где n - регистр сдвига, а k - количество измерений вектора. Фонема соответствует той,
	которая относится к последнему вошедшему в окно сдвига вектору.
	2) Убрать векторное квантование.
	3) При конвертации сравнивать матрицу не со средней, а со всеми для каждой фонемы с учётом некоторой расфокусировки
	(отклонения элемента a_ij от b_ij для всех i и j). Как определить эту расфокусировку - чёрт её знает. Может, стоит
	использовать не разницу между каждым элементом, а некоторую максимально возможную разницу расстояний для этих двух 
	матриц? Как тогда это расстояние искать? Я не очень себе представляю матрицу в виде точки (в отличие от вектора). Подумать над этим.
	4) Как сделать расфокусировку обучаемой? 
	5) Алгоритм DTW нам не нужен.
	
	Личные заметки: уже то, что мы напишем можно будет использовать для распознавания речи 
	(если потом ещё анализировать созданные нами нейроны и контролировать их). Тогда зачем нам ДАЗУ? Я думал, наша задача - создать материал 
	для её обучения. А по итогу мы уже обучаем собственную программу. Я запутался. Всё отличие ДАЗУ от конвертирующего приложения как раз в 
	том, что она умеет работать с созданными нейронами?