Текущие задачи:
	
	1) В базу данных обучения записывать вместо всех встретившихся векторов, соответствующих данной фонеме, 
	записывать все матрицы размера n*k, где n - регистр сдвига, а k - количество измерений вектора. Фонема соответствует той,
	которая относится к последнему вошедшему в окно сдвига вектору.
	2) Убрать векторное квантование.
	3) При конвертации сравнивать матрицу не со средней, а со всеми для каждой фонемы с учётом некоторой расфокусировки
	(отклонения элемента a_ij от b_ij для всех i и j). Как определить эту расфокусировку - чёрт её знает. Может, стоит
	использовать не разницу между каждым элементом, а некоторую максимально возможную разницу расстояний для этих двух 
	матриц? Как тогда это расстояние искать? Я не очень себе представляю матрицу в виде точки (в отличие от вектора). Подумать над этим.
	
	Из одной матрицы вычитается другая (поэлементно) и берется ее норма. Это расстояние между матрицами. Если оно не превышает радиуса расфокусировки, считать за одно.
	В пространстве размерности nxk матрица - это точка.
	
	4) Как сделать расфокусировку обучаемой?
	
	Смотреть, сколько матриц при распознавании будет совпадать, и увеличивать радиус расфокусировки до тех пор, пока совпадений будет достаточно.
	
	5) Алгоритм DTW нам не нужен.
	
	Личные заметки: уже то, что мы напишем можно будет использовать для распознавания речи 
	(если потом ещё анализировать созданные нами нейроны и контролировать их). Тогда зачем нам ДАЗУ? Я думал, наша задача - создать материал 
	для её обучения. А по итогу мы уже обучаем собственную программу. Я запутался. Всё отличие ДАЗУ от конвертирующего приложения как раз в 
	том, что она умеет работать с созданными нейронами?
	
	Действительно, модель ДАЗУ будет не нужна. Да и работать конверирующее приложение будет быстрее. ДАЗУ было нужно исключительно для понимания, что надо делать.
